{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKBZMjlb_6Jk"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <h1>Welcom to SSCMA for Google Colab Training Example üî• </h1>\n",
        "  <a href=\"https://sensecraftma.seeed.cc/\" target=\"_blank\"><img width=\"20%\" src=\"https://files.seeedstudio.com/sscma/docs/images/SSCMA-Hero.png\"></a>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBZwN90j_6Jo"
      },
      "source": [
        "# COCO Detection - Swift-YOLO\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seeed-studio/sscma-model-zoo/blob/main/notebooks/en/COCO_Detection_Swift-YOLO_320.ipynb)\n",
        "\n",
        "**Version:** 1.0.0\n",
        "\n",
        "**Category:** Object Detection\n",
        "\n",
        "**Algorithm:** [Swift-YOLO](configs/yolov5/swift_yolo_shuff_1xb16_300e_coco.py)\n",
        "\n",
        "**Dataset:** [COCO2017](https://public.roboflow.com/object-detection/microsoft-coco-subset)\n",
        "\n",
        "**Class:** `person`\n",
        "\n",
        "![COCO Detection](https://files.seeedstudio.com/sscma/static/detection_coco.png)\n",
        "\n",
        "The model is a Swift-YOLO model trained on the COCO2017 dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATIZGjRD_6Jp"
      },
      "source": [
        "## ‚öôÔ∏èPrerequisites\n",
        "### Setup SSCMA\n",
        "Clone the [repository](https://github.com/Seeed-Studio/ModelAssistant) and install the dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY3gGQyM_6Jp",
        "outputId": "3fe333cf-da5a-4629-8a67-c0bb837c0ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ethos-u-vela'...\n",
            "remote: Counting objects: 80, done\u001b[K\n",
            "remote: Finding sources: 100% (10824/10824)\u001b[K\n",
            "remote: Total 10824 (delta 6916), reused 9357 (delta 6916)\u001b[K\n",
            "Receiving objects: 100% (10824/10824), 5.76 MiB | 14.73 MiB/s, done.\n",
            "Resolving deltas: 100% (6916/6916), done.\n",
            "/content/ethos-u-vela\n",
            "Processing /content/ethos-u-vela\n"
          ]
        }
      ],
      "source": [
        "# Ethos-U-Vela need to be installed this way, or SSCMA does not work anymore...\n",
        "!git clone https://review.mlplatform.org/ml/ethos-u/ethos-u-vela.git\n",
        "%cd ethos-u-vela\n",
        "!pip install .\n",
        "%cd ..\n",
        "\n",
        "!git clone https://github.com/Seeed-Studio/ModelAssistant.git -b 2.0.0  #clone the repo\n",
        "%cd ModelAssistant\n",
        "!. ./scripts/setup_colab.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSypCmrH_6Jq"
      },
      "source": [
        "### Download the pretrain model weights file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfjUJdzA_6Jr",
        "outputId": "e8827eb7-e8c7-4980-c68c-b6e23585e92d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-11 11:17:29--  https://files.seeedstudio.com/sscma/model_zoo/detection/coco/swift_yolo_shuffle_coco_320_float32_sha1_a5927bd6a6c6569d27edb98da946a8e75a8d816f.pth\n",
            "Resolving files.seeedstudio.com (files.seeedstudio.com)... 108.156.83.79, 108.156.83.47, 108.156.83.95, ...\n",
            "Connecting to files.seeedstudio.com (files.seeedstudio.com)|108.156.83.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77669861 (74M) [application/octet-stream]\n",
            "Saving to: ‚ÄòCOCO_Detection_Swift-YOLO_320/pretrain.pth‚Äô\n",
            "\n",
            "COCO_Detection_Swif 100%[===================>]  74.07M  29.5MB/s    in 2.5s    \n",
            "\n",
            "2025-05-11 11:17:32 (29.5 MB/s) - ‚ÄòCOCO_Detection_Swift-YOLO_320/pretrain.pth‚Äô saved [77669861/77669861]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%mkdir -p COCO_Detection_Swift-YOLO_320\n",
        "!wget -c https://files.seeedstudio.com/sscma/model_zoo/detection/coco/swift_yolo_shuffle_coco_320_float32_sha1_a5927bd6a6c6569d27edb98da946a8e75a8d816f.pth -O COCO_Detection_Swift-YOLO_320/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYx5qNNj_6Jr"
      },
      "source": [
        "### Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ySU6sYD_6Js",
        "outputId": "a45bbb1d-9234-4a61-b8c2-e00835b3feda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-14 07:04:26--  https://app.roboflow.com/ds/4zE3Lox6wd?key=MmsOLwVLhk\n",
            "Resolving app.roboflow.com (app.roboflow.com)... 151.101.1.195, 151.101.65.195, 2620:0:890::100\n",
            "Connecting to app.roboflow.com (app.roboflow.com)|151.101.1.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com/roboflow-platform-regional-exports/cWx23FtU5MS6tJpR598CS5gzDqh2/fNb9H5hV1zmFiOBlcUZ4/1/coco.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=481589474394-compute%40developer.gserviceaccount.com%2F20250514%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250514T070426Z&X-Goog-Expires=900&X-Goog-SignedHeaders=host&X-Goog-Signature=5ae76fa3c94df7e48cd521e29993ca92c6708a63d47275965c6c8239b20c9c1971d87374d13e05f5811b44cfbc584630d5c511ce21793c58390d3342c73a13d003ec5e18670c84020e221671e77bb390f776900b9020246c5c2f46544ea85505bd56e2a704689dcff1d07a76d9191ef44a653b3446dad51aac232075bfe77c0c26d981435c65316fa44d767ef3ab367d1d611e146c922f548db3c03922005ea9dae01f5550b85fa342493078c379cc60909412825a9ff2d610b504ef5e88c24a17ad75de07c952ed205dda61d3e8e53073e323339b9f00cafcbc20d137569e91f53e23bd1ea6757711cd256b595c9799ad46116efca2c2b984406ff0834b83d4 [following]\n",
            "--2025-05-14 07:04:26--  https://storage.googleapis.com/roboflow-platform-regional-exports/cWx23FtU5MS6tJpR598CS5gzDqh2/fNb9H5hV1zmFiOBlcUZ4/1/coco.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=481589474394-compute%40developer.gserviceaccount.com%2F20250514%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20250514T070426Z&X-Goog-Expires=900&X-Goog-SignedHeaders=host&X-Goog-Signature=5ae76fa3c94df7e48cd521e29993ca92c6708a63d47275965c6c8239b20c9c1971d87374d13e05f5811b44cfbc584630d5c511ce21793c58390d3342c73a13d003ec5e18670c84020e221671e77bb390f776900b9020246c5c2f46544ea85505bd56e2a704689dcff1d07a76d9191ef44a653b3446dad51aac232075bfe77c0c26d981435c65316fa44d767ef3ab367d1d611e146c922f548db3c03922005ea9dae01f5550b85fa342493078c379cc60909412825a9ff2d610b504ef5e88c24a17ad75de07c952ed205dda61d3e8e53073e323339b9f00cafcbc20d137569e91f53e23bd1ea6757711cd256b595c9799ad46116efca2c2b984406ff0834b83d4\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.121.207, 209.85.145.207, 142.251.183.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.121.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1169215 (1.1M) [application/zip]\n",
            "Saving to: ‚ÄòCOCO_Detection_Swift-YOLO_320/dataset.zip‚Äô\n",
            "\n",
            "COCO_Detection_Swif 100%[===================>]   1.11M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-05-14 07:04:26 (109 MB/s) - ‚ÄòCOCO_Detection_Swift-YOLO_320/dataset.zip‚Äô saved [1169215/1169215]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%mkdir -p COCO_Detection_Swift-YOLO_320/dataset\n",
        "!wget -c https://app.roboflow.com/ds/4zE3Lox6wd?key=MmsOLwVLhk -O COCO_Detection_Swift-YOLO_320/dataset.zip\n",
        "!unzip -q COCO_Detection_Swift-YOLO_320/dataset.zip -d COCO_Detection_Swift-YOLO_320/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xlQBWup_6Jt"
      },
      "source": [
        "## üöÄTrain a model with SSCMA\n",
        "All the training parameters are in the `config.py` file, you can change the parameters to train your own model.\n",
        "\n",
        "Below are explanations of some common parameters. You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/config) for more details.\n",
        "- `data_root` - the datasets path.\n",
        "- `epochs`- the train epochs. **we use 10 epochs as an example**.\n",
        "- `batch_size` - the batch size.\n",
        "- `height` - the image height.\n",
        "- `width` - the image width.\n",
        "- `load_from` - the pretrained model path.\n",
        "- `num_classes` - the number of classes.\n",
        "\n",
        "You can overwrite the parameters in the `config.py` file by using the `--cfg-options` argument.\n",
        "```bash\n",
        "# Example\n",
        "sscma.train config.py --cfg-options data_root=./datasets/test_dataset epochs=10\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scAT5gsk_6Jt",
        "outputId": "8e9fe0de-33ed-4f14-dc98-7a9d356dcf3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: sscma.train: command not found\n"
          ]
        }
      ],
      "source": [
        "!sscma.train configs/yolov5/swift_yolo_shuff_1xb16_300e_coco.py \\\n",
        "--cfg-options  \\\n",
        "    work_dir=COCO_Detection_Swift-YOLO_320 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=10  \\\n",
        "    height=320 \\\n",
        "    width=320 \\\n",
        "    data_root=COCO_Detection_Swift-YOLO_320/dataset/ \\\n",
        "    load_from=COCO_Detection_Swift-YOLO_320/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTzu-KwK_6Jt"
      },
      "source": [
        "## üì¶Export the model\n",
        "After training, you can export the model to the format for deployment. SSCMA supports exporting to ONNX, and TensorFlow Lite at present.\n",
        "You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n",
        "\n",
        "```bash\n",
        "python3 tools/export.py \\\n",
        "    \"<CONFIG_FILE_PATH>\" \\\n",
        "    \"<CHECKPOINT_FILE_PATH>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "RLFJC3HN_6Jt",
        "outputId": "e524f8c0-98ff-4e4f-a173-59249345b1fa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'COCO_Detection_Swift-YOLO_320/last_checkpoint'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-816d17007a07>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COCO_Detection_Swift-YOLO_320/last_checkpoint'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CHECKPOINT_FILE_PATH'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'COCO_Detection_Swift-YOLO_320/last_checkpoint'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "with open('COCO_Detection_Swift-YOLO_320/last_checkpoint', 'r') as f:\n",
        "\tos.environ['CHECKPOINT_FILE_PATH'] = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_f7-gE1_6Ju"
      },
      "outputs": [],
      "source": [
        "!sscma.export configs/yolov5/swift_yolo_shuff_1xb16_300e_coco.py $CHECKPOINT_FILE_PATH --cfg-options  \\\n",
        "    work_dir=COCO_Detection_Swift-YOLO_320 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=10  \\\n",
        "    height=320 \\\n",
        "    width=320 \\\n",
        "    data_root=COCO_Detection_Swift-YOLO_320/dataset/ \\\n",
        "    load_from=COCO_Detection_Swift-YOLO_320/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzfAVd62_6Ju"
      },
      "source": [
        "### üìùEvaluate the model\n",
        "After exporting the model, you can evaluate the model on the test dataset.\n",
        "You can also refer to the [documentation](https://sensecraftma.seeed.cc/tutorials/export/overview) for more details.\n",
        "\n",
        "\n",
        "```bash\n",
        "python3 tools/inference.py \\\n",
        "    \"<CONFIG_FILE_PATH>\" \\\n",
        "    \"<CHECKPOINT_FILE_PATH>\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFe7iMwj_6Ju"
      },
      "source": [
        "### Evaluate the PyTorch model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2327Wx5J_6Ju"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/yolov5/swift_yolo_shuff_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}.pth \\\n",
        "--cfg-options  \\\n",
        "    work_dir=COCO_Detection_Swift-YOLO_320 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=10  \\\n",
        "    height=320 \\\n",
        "    width=320 \\\n",
        "    data_root=COCO_Detection_Swift-YOLO_320/dataset/ \\\n",
        "    load_from=COCO_Detection_Swift-YOLO_320/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9ok4kN1_6Ju"
      },
      "source": [
        "### Evaluate the ONNX model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYIsOteS_6Ju"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/yolov5/swift_yolo_shuff_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.onnx \\\n",
        "--cfg-options  \\\n",
        "    work_dir=COCO_Detection_Swift-YOLO_320 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=10  \\\n",
        "    height=320 \\\n",
        "    width=320 \\\n",
        "    data_root=COCO_Detection_Swift-YOLO_320/dataset/ \\\n",
        "    load_from=COCO_Detection_Swift-YOLO_320/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vItCu3NV_6Ju"
      },
      "source": [
        "### Evaluate the TFLite FLOAT32 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfPxheIb_6Jv"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/yolov5/swift_yolo_shuff_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.tflite \\\n",
        "--cfg-options  \\\n",
        "    work_dir=COCO_Detection_Swift-YOLO_320 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=10  \\\n",
        "    height=320 \\\n",
        "    width=320 \\\n",
        "    data_root=COCO_Detection_Swift-YOLO_320/dataset/ \\\n",
        "    load_from=COCO_Detection_Swift-YOLO_320/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n34pTFI_6Jv"
      },
      "source": [
        "### Evaluate the TFLite INT8 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCsi5Wad_6Jv"
      },
      "outputs": [],
      "source": [
        "!sscma.inference configs/yolov5/swift_yolo_shuff_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_int8.tflite \\\n",
        "--cfg-options  \\\n",
        "    work_dir=COCO_Detection_Swift-YOLO_320 \\\n",
        "    num_classes=1 \\\n",
        "    epochs=10  \\\n",
        "    height=320 \\\n",
        "    width=320 \\\n",
        "    data_root=COCO_Detection_Swift-YOLO_320/dataset/ \\\n",
        "    load_from=COCO_Detection_Swift-YOLO_320/pretrain.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx1TyxEv_6Jv"
      },
      "source": [
        "## ü§ñ Deploy the model\n",
        "After model training, evaluation and export, you can deploy the model to your device. You can refer to [Documentation](https://sensecraftma.seeed.cc/deploy/overview) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhBUlh_l_6Jv"
      },
      "outputs": [],
      "source": [
        "%ls -lh COCO_Detection_Swift-YOLO_320/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26bAezo7_6Jv"
      },
      "source": [
        "### Thanks for Trying Out SSCMA üéâ\n",
        "\n",
        "Congratulations, you have completed this tutorial. If you are interested in more application scenarios or our projects, please feel free to give [SSCMA](https://github.com/Seeed-Studio/ModelAssistant) a star ‚ú® on GitHub.\n",
        "\n",
        "If you have any questions about this tutorial, please also feel free to [submit an issue](https://github.com/Seeed-Studio/ModelAssistant/issues)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}